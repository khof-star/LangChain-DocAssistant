# ğŸ¤– LangChain Smart Document Assistant

A **Streamlit + LangChain-powered AI application** that reads PDFs, extracts embeddings, retrieves context, and auto-formats intelligent responses using zero-shot routing and parallel LLM generation.

---

## ğŸ§© Project Structure

```

my_project/
â”‚
â”œâ”€â”€ app.py                  # Main Streamlit application
â”œâ”€â”€ auto_formatter.py       # Detects format type (email, report, paper, etc.)
â”œâ”€â”€ format_router.py        # Uses zero-shot classification to route templates
â”œâ”€â”€ parallel_generate.py    # Executes multiple LangChain RetrievalQA chains in parallel
â”œâ”€â”€ htmlTemplates.py        # Stores HTML & CSS chat message templates
â”œâ”€â”€ style.css               # Styling for the Streamlit/HTML UI
â”œâ”€â”€ .env                    # Private API keys or environment variables
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ **pycache**/            # Auto-generated by Python

````

---

## ğŸ› ï¸ Installation Steps

> Run the following commands in your terminal.  
> Make sure you have **Python 3.10+** installed.

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/LangChain-DocAssistant.git
cd LangChain-DocAssistant
````

### 2ï¸âƒ£ Create and Activate a Virtual Environment

```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Setup Environment Variables

Create a `.env` file in the project root:

```bash
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_token_here
```

### 5ï¸âƒ£ Run the App

```bash
streamlit run app.py
```

---

## âš™ï¸ How It Works

| Step  | Module                 | Description                                                                                                    |
| ----- | ---------------------- | -------------------------------------------------------------------------------------------------------------- |
| **1** | `app.py`               | Main entry point (Streamlit UI + PDF upload + LLM setup)                                                       |
| **2** | `format_router.py`     | Routes input queries to correct output templates using **zero-shot classification (facebook/bart-large-mnli)** |
| **3** | `auto_formatter.py`    | Detects and defines format type (e.g., report, research paper, project plan)                                   |
| **4** | `parallel_generate.py` | Runs multiple candidate templates **in parallel** using ThreadPoolExecutor for best answer                     |
| **5** | `htmlTemplates.py`     | Defines user/bot chat bubbles and CSS styling                                                                  |
| **6** | `style.css`            | Adds theme and UI styling for clean chat interface                                                             |

---

## ğŸ§  Core Features

* ğŸ§¾ **Multi-format Output**: Detects content type (email, report, project plan, etc.)
* âš¡ **Parallel LLM Processing**: Uses threading for fast template generation
* ğŸ” **LangChain RetrievalQA**: Retrieves relevant text chunks from PDF embeddings
* ğŸ§© **Zero-Shot Format Routing**: Uses Hugging Face `facebook/bart-large-mnli`
* ğŸ’¬ **Styled Chat Interface**: With avatars and smooth message layout
* ğŸ” **Environment Safe**: Keys stored in `.env`

---

## ğŸ§± Tech Stack

| Component                    | Library                   |
| ---------------------------- | ------------------------- |
| **Frontend/UI**              | Streamlit, HTML, CSS      |
| **Backend Logic**            | Python 3, LangChain       |
| **AI Models**                | OpenAI / HuggingFace LLMs |
| **Vector Store**             | FAISS                     |
| **Parallel Execution**       | ThreadPoolExecutor        |
| **Zero-Shot Classification** | facebook/bart-large-mnli  |

---

## ğŸ§­ Architecture Overview

```
ğŸ“„ PDF Files
   â†“
ğŸ“š Split into Chunks
   â†“
ğŸ§  Embedding Generation
   â†“
ğŸ—„ï¸ Vector Store (FAISS)
   â†“
ğŸ§© Query â†’ Format Detection (auto_formatter.py)
   â†“
ğŸ” Zero-Shot Routing (format_router.py)
   â†“
âš™ï¸ Parallel Retrieval + LLM (parallel_generate.py)
   â†“
ğŸ’¬ HTML Templates (htmlTemplates.py)
   â†“
ğŸ¨ Streamlit Interface (app.py + style.css)
```

---

## ğŸ“¦ Example Output

**User Input:**

> â€œSummarize this PDF into a 3-point research conclusion.â€

**Auto Detected Format:**

> `research_paper`

**Generated Output:**

```
ğŸ“š RESEARCH PAPER SUMMARY
Title: [auto-filled]
Authors: [detected]
Journal: [found in context]
Key Findings:
1. ...
2. ...
3. ...
Conclusion: ...
```

---

## ğŸ§‘â€ğŸ’» Contributing

Pull requests are welcome!
To add a new format:

1. Edit `auto_formatter.py` â†’ add keywords.
2. Update `format_router.py` â†’ add label + template.
3. Run `streamlit run app.py` to test.

---

## ğŸ§© Future Improvements

* [ ] Add multilingual prompt templates
* [ ] Integrate local embeddings with ChromaDB
* [ ] Implement async LLM calls for better concurrency
* [ ] Add dark/light toggle in UI

---

## ğŸ§¾ License

MIT License Â© 2025 **Navin Bharti**

---

## ğŸŒ Connect

* ğŸ”— [LinkedIn](https://linkedin.com/in/navinbharti)
* ğŸ’» [GitHub](https://github.com/your-username)
* ğŸ“§ Email: [your.email@example.com](mailto:your.email@example.com)

```

---

### âœ… Features of This README
- 100% Markdown-compatible with GitHub  
- Has syntax-highlighted code blocks, emoji headers, and architecture diagram  
- Explains every file in your project clearly  
- Ready to publish directly on GitHub  

Would you like me to add **GitHub badges** (like Python version, Streamlit app status, last commit, stars, etc.) at the top for a more professional look?
```
