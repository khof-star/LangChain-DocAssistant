# 🤖 LangChain Smart Document Assistant

A **Streamlit + LangChain-powered AI application** that reads PDFs, extracts embeddings, retrieves context, and auto-formats intelligent responses using zero-shot routing and parallel LLM generation.

---

## 🧩 Project Structure

```

my_project/
│
├── app.py                  # Main Streamlit application
├── auto_formatter.py       # Detects format type (email, report, paper, etc.)
├── format_router.py        # Uses zero-shot classification to route templates
├── parallel_generate.py    # Executes multiple LangChain RetrievalQA chains in parallel
├── htmlTemplates.py        # Stores HTML & CSS chat message templates
├── style.css               # Styling for the Streamlit/HTML UI
├── .env                    # Private API keys or environment variables
├── requirements.txt        # Python dependencies
└── **pycache**/            # Auto-generated by Python

````

---

## 🛠️ Installation Steps

> Run the following commands in your terminal.  
> Make sure you have **Python 3.10+** installed.

### 1️⃣ Clone the Repository
```bash
git clone https://github.com/your-username/LangChain-DocAssistant.git
cd LangChain-DocAssistant
````

### 2️⃣ Create and Activate a Virtual Environment

```bash
python -m venv venv
# On Windows
venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate
```

### 3️⃣ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4️⃣ Setup Environment Variables

Create a `.env` file in the project root:

```bash
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACEHUB_API_TOKEN=your_huggingface_api_token_here
```

### 5️⃣ Run the App

```bash
streamlit run app.py
```

---

## ⚙️ How It Works

| Step  | Module                 | Description                                                                                                    |
| ----- | ---------------------- | -------------------------------------------------------------------------------------------------------------- |
| **1** | `app.py`               | Main entry point (Streamlit UI + PDF upload + LLM setup)                                                       |
| **2** | `format_router.py`     | Routes input queries to correct output templates using **zero-shot classification (facebook/bart-large-mnli)** |
| **3** | `auto_formatter.py`    | Detects and defines format type (e.g., report, research paper, project plan)                                   |
| **4** | `parallel_generate.py` | Runs multiple candidate templates **in parallel** using ThreadPoolExecutor for best answer                     |
| **5** | `htmlTemplates.py`     | Defines user/bot chat bubbles and CSS styling                                                                  |
| **6** | `style.css`            | Adds theme and UI styling for clean chat interface                                                             |

---

## 🧠 Core Features

* 🧾 **Multi-format Output**: Detects content type (email, report, project plan, etc.)
* ⚡ **Parallel LLM Processing**: Uses threading for fast template generation
* 🔍 **LangChain RetrievalQA**: Retrieves relevant text chunks from PDF embeddings
* 🧩 **Zero-Shot Format Routing**: Uses Hugging Face `facebook/bart-large-mnli`
* 💬 **Styled Chat Interface**: With avatars and smooth message layout
* 🔐 **Environment Safe**: Keys stored in `.env`

---

## 🧱 Tech Stack

| Component                    | Library                   |
| ---------------------------- | ------------------------- |
| **Frontend/UI**              | Streamlit, HTML, CSS      |
| **Backend Logic**            | Python 3, LangChain       |
| **AI Models**                | OpenAI / HuggingFace LLMs |
| **Vector Store**             | FAISS                     |
| **Parallel Execution**       | ThreadPoolExecutor        |
| **Zero-Shot Classification** | facebook/bart-large-mnli  |

---

## 🧭 Architecture Overview

```
📄 PDF Files
   ↓
📚 Split into Chunks
   ↓
🧠 Embedding Generation
   ↓
🗄️ Vector Store (FAISS)
   ↓
🧩 Query → Format Detection (auto_formatter.py)
   ↓
🔍 Zero-Shot Routing (format_router.py)
   ↓
⚙️ Parallel Retrieval + LLM (parallel_generate.py)
   ↓
💬 HTML Templates (htmlTemplates.py)
   ↓
🎨 Streamlit Interface (app.py + style.css)
```

---

## 📦 Example Output

**User Input:**

> “Summarize this PDF into a 3-point research conclusion.”

**Auto Detected Format:**

> `research_paper`

**Generated Output:**

```
📚 RESEARCH PAPER SUMMARY
Title: [auto-filled]
Authors: [detected]
Journal: [found in context]
Key Findings:
1. ...
2. ...
3. ...
Conclusion: ...
```

---

## 🧑‍💻 Contributing

Pull requests are welcome!
To add a new format:

1. Edit `auto_formatter.py` → add keywords.
2. Update `format_router.py` → add label + template.
3. Run `streamlit run app.py` to test.

---

## 🧩 Future Improvements

* [ ] Add multilingual prompt templates
* [ ] Integrate local embeddings with ChromaDB
* [ ] Implement async LLM calls for better concurrency
* [ ] Add dark/light toggle in UI

---

## 🧾 License

MIT License © 2025 **Navin Bharti**

---

## 🌐 Connect

* 🔗 [LinkedIn](https://linkedin.com/in/navinbharti)
* 💻 [GitHub](https://github.com/your-username)
* 📧 Email: [your.email@example.com](mailto:your.email@example.com)

```

---

### ✅ Features of This README
- 100% Markdown-compatible with GitHub  
- Has syntax-highlighted code blocks, emoji headers, and architecture diagram  
- Explains every file in your project clearly  
- Ready to publish directly on GitHub  

Would you like me to add **GitHub badges** (like Python version, Streamlit app status, last commit, stars, etc.) at the top for a more professional look?
```
